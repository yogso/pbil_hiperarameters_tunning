{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFM Julio.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yogso/pbil_hiperarameters_tunning/blob/master/Hiperparameters%20Tunning%20via%20PBIL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI-95SHw9JHU",
        "colab_type": "code",
        "outputId": "6af89735-081d-4832-a4ed-6b45b3fe578e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!pip install stldecompose"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: stldecompose in /usr/local/lib/python3.6/dist-packages (0.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stldecompose) (1.16.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from stldecompose) (0.24.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from stldecompose) (3.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from stldecompose) (1.3.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (from stldecompose) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->stldecompose) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->stldecompose) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stldecompose) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stldecompose) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stldecompose) (2.4.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels->stldecompose) (0.5.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas->stldecompose) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->stldecompose) (41.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8_Dx3i-8wr3",
        "colab_type": "code",
        "outputId": "d533c736-15ce-4f8b-d996-fcb2f702c68b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib notebook\n",
        "import random as rn\n",
        "import math\n",
        "\n",
        "from keras.backend import clear_session\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, concatenate, Input\n",
        "from keras.layers import Convolution1D, MaxPooling1D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['xtick.labelsize'] = 'large'\n",
        "mpl.rcParams['ytick.labelsize'] = 'large'\n",
        "mpl.rcParams['axes.labelsize'] = 'large'\n",
        "\n",
        "\"\"\"The imports: personal libraries\"\"\"\n",
        "#np.set_printoptions(threshold=np.inf)\n",
        "\n",
        "from stldecompose import decompose, forecast   #pip install stldecompose\n",
        "from stldecompose.forecast_funcs import (naive,\n",
        "                                         drift, \n",
        "                                         mean, \n",
        "                                         seasonal_naive)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B728AnYH8wr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = [90, 79, 99, 117, 99, 99, 86, 95, 93, 69, 87, 94, 74, 90, 76, 71, 87, 60, 72, 73, 77, 51, 66, 58, 63, 52.5, 67, 63, 78, 84, 69, 75, \n",
        "77, 71, 82, 85, 82, 81.5, 94, 99, 97, 78, 93.5, 80, 92, 74, 71, 83, 70, 80, 86, 61, 77.6969111969112, 70, 83, 95, 82, 86, 83, 83, 82, 79, 101, \n",
        "122, 100, 74, 70, 70, 70, 74, 73, 83, 66, 60, 66, 62, 60, 69, 67, 71, 68, 60, 68, 73, 66, 67, 72, 77, 67, 47, 68, 85.5, 84, 78, 89, 81, 61, \n",
        "75, 99, 104, 83, 77.6969111969112, 62, 70, 91, 98, 103, 112, 105, 111, 109, 99, 110, 88, 82.5, 99, 81, 79, 72, 80, 75, 86, 77, 61, 56, 55, 66, \n",
        "60, 71, 71, 74, 72, 54, 65, 74, 75, 76, 72, 69, 78.5, 67, 72, 63, 69, 87, 71, 71, 72.5, 75, 93, 89, 100, 96, 96, 101, 102, 70.5, 72, 74, 67, \n",
        "68, 70, 65, 75.5, 72, 65, 80, 95, 94.5, 71, 84.5, 81, 78, 71, 66, 83, 85, 62, 73, 80, 69, 66, 63, 63, 69, 68, 78.5, 78, 78, 79, 67, 69, 82, \n",
        "78, 61, 73.5, 70, 79, 81.5, 83, 90, 79, 99, 97, 95, 67, 79.5, 65, 80, 74, 70.5, 79, 78, 104, 77, 74, 87, 84, 94, 109, 91, 93.5, 95, 76, 72, \n",
        "61, 57, 59, 70, 68, 82, 67, 69, 73, 76, 70, 57, 75, 63, 72, 64, 66, 70, 81, 68, 74, 72, 79, 84, 81, 69, 77, 74, 97, 103, 107, 88, 96, 101]\n",
        "\n",
        "date = pd.date_range(start='7/1/2013', freq='W', periods=259)\n",
        "df = pd.DataFrame(dataset, index=date)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTzUbDiFFhm4",
        "colab_type": "code",
        "outputId": "8921f341-66a2-4aac-bb4a-85c88fa3a4ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "259"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDc0hZsr8wr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hiperparametros a optimizar [Nombre del hiperparametro, rango desde <=, rango hasta >=, con paso]\n",
        "\n",
        "\n",
        "hiperparametros = [\n",
        "    [\"batch_size\", 40, 71, 1],\n",
        "    [\"lo_frac\", 0, 1, 0.1],\n",
        "    [\"period\", 30, 61, 1],\n",
        "    [\"lo_delta\", 0, 0.2, 0.01],\n",
        "    \n",
        "    #Sample_size debe ser minimo 52, debido a que como en cada capa de la red convolucional se reduce la dimensionalidad,\n",
        "    #entonces 52 es la minima dimension para que existan elementos en la capa de salida. Por este mismo motivo los kernels deben ser pequeños\n",
        "    [\"sample_size\", 52, 100, 2],\n",
        "    [\"epoch\", 20, 140, 20],\n",
        "    [\"learning_rate\", 0.001, 0.05, 0.005],\n",
        "    [\"lr_decay\", 0.0, 0.001, 0.0001],\n",
        "    [\"kernel1\", 1, 10, 1],\n",
        "    [\"kernel2\", 1, 6, 1],\n",
        "    [\"kernel3\", 1, 3, 1],\n",
        "    [\"filtro1\", 10, 50, 5],\n",
        "    [\"filtro2\", 30, 80, 10],\n",
        "    [\"filtro3\", 60, 160, 20]\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "##Valores por defecto:\n",
        "#lo_delta=0.01\n",
        "#batch_size = 50\n",
        "#period = 5\n",
        "#lo_frac = 0.6\n",
        "#sample_size = 52\n",
        "#epoch=100\n",
        "#learning_rate=0.001\n",
        "#lr_decay=0.0\n",
        "#kernel1 = 9\n",
        "#kernel2 = 5\n",
        "#kernel3 = 3\n",
        "#filtro1 = 32\n",
        "#filtro2 = 64\n",
        "#filtro3 = 128\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycjh1xo98wsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "\n",
        "generaciones = pd.DataFrame(columns=['Generacion','MSE'])\n",
        "\n",
        "#generaciones = pd.read_pickle('data_mayo/generationes_periodo_batchsize_nuevo_3.pkl')\n",
        "\n",
        "def pbil_optimizacion(learn_rate, learn_rate_neg, num_pob, num_mejores_para_actualizar_vec, num_peores_para_actualizar_vec, vec_len,\n",
        "             ciclos_optimizacion, eval_f, eps=0.01, lista_vecs=None):\n",
        "    \"\"\"\n",
        "    learn_rate: tasa de actualización del vector poblacional (vec) hacia cada uno de los mejores individuos.\n",
        "    learn_rate_neg: similar a learn_rate, pero para alejar el vector de los peores individuos.\n",
        "    num_pob: número de individuos en cada población\n",
        "    num_mejores_para_actualizar_vec: ¿cuántos mejores individuos se utilizarán para actualizar el vector poblacional?\n",
        "    num_peores_para_actualizar_vec: ¿cuántos de los peores individuos se utilizarán para actualizar el vector poblacional?\n",
        "    vec_len: longitud del vector de población\n",
        "    ciclos_optimizacion: numero de ciclos de optimizacion\n",
        "    eval_f: función para la evaluación del fitness de cada individuo\n",
        "    eps: el vector poblacional será alejado de los valores extremos (0, 1) sumando o restando un valor eps determinado.\n",
        "    lista_vecs: almacena los vectores de población de cada generación.\n",
        "    \"\"\"\n",
        "    global generaciones\n",
        "    secciones = [row[2] for row in hiperparametros_int_aux]\n",
        "    \n",
        "    # Inicialización del vector\n",
        "    vec = crea_prob_inicial(vec_len)\n",
        "\n",
        "    # Inicialización de la población\n",
        "    poblacion = pob_ini(num_pob, vec_len)\n",
        "    scores = scores_ini(num_pob)\n",
        "    modelos = [None] * num_pob\n",
        "    hipers = [None] * num_pob\n",
        "\n",
        "    # Inicializar mejor resultado\n",
        "    # Contendrá: [Valoración, vector binario del individuo, modelo entrenado, hiperparametros en decimales]\n",
        "    mejor_de_todos = [float(\"inf\"), None]\n",
        "\n",
        "    lista_vecs = [vec]\n",
        "\n",
        "    for i in range(ciclos_optimizacion):\n",
        "        for j in range(num_pob):\n",
        "      #      poblacion[j] = get_num(vec)\n",
        "\n",
        "            poblacion[j][0:secciones[0]] = get_num(vec[0:secciones[0]])\n",
        "            anterior = secciones[0]\n",
        "            indx=1\n",
        "            while indx < len(secciones):\n",
        "                poblacion[j][anterior:secciones[indx]+anterior] = get_num(vec[anterior:secciones[indx]+anterior], indx= indx)\n",
        "                anterior = anterior + secciones[indx]\n",
        "                indx+=1\n",
        "            \n",
        "            # Evaluaciones de los individuos\n",
        "            scores[j], modelos[j], hipers[j] = eval_f(poblacion[j])\n",
        "        # Selección de los mejores indiviuos\n",
        "        results_ordenados = sorted(zip(scores, poblacion, modelos, hipers), key=lambda x:x[0], reverse=False)\n",
        "        mejor = results_ordenados[:num_mejores_para_actualizar_vec]\n",
        "        worst = results_ordenados[-num_peores_para_actualizar_vec:]\n",
        "\n",
        "        if mejor_de_todos[0] > mejor[0][0]:\n",
        "            mejor_de_todos = (mejor[0][0], list(mejor[0][1]), mejor[0][2], mejor[0][3])\n",
        "            \n",
        "        print('Paso: {0}'.format(i))\n",
        "        print('Vector de prob: {0}'.format(vec))\n",
        "        print('Mejores: {0}'.format([(b[0]) for b in mejor]))\n",
        "        print('Peores: {0}'.format([(w[0]) for w in worst]))\n",
        "        print('Mejor de todos: {0}'.format((mejor_de_todos[0])))\n",
        "        print(\"--------------\")\n",
        "        \n",
        "        # Actualizar vector\n",
        "        for v in mejor:\n",
        "            vec += 2 * learn_rate * (v[1] - 0.5)\n",
        "        for v in worst:\n",
        "            vec -= 2 * learn_rate_neg * (v[1] - 0.5)\n",
        "\n",
        "        # Corrección del vector si hay elementos fuera del rango [0, 1]\n",
        "        for j in range(vec_len):\n",
        "            if vec[j] < 0:\n",
        "                vec[j] = 0 + eps\n",
        "            elif vec[j] > 1:\n",
        "                vec[j] = 1 - eps\n",
        "\n",
        "        # Añadir vec\n",
        "        lista_vecs.append(vec)\n",
        "        \n",
        "        generaciones = generaciones.append({'Generacion':i+1,\n",
        "                            'MSE':mejor_de_todos[0]}, ignore_index=True)\n",
        "        \n",
        "        #generaciones.to_pickle('data_mayo/generationes_periodo_batchsize_nuevo_3.pkl')\n",
        "                \n",
        "    return mejor_de_todos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLO2vmRh8wsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Inicialización y entrenamiento de cada modelo\n",
        "\n",
        "def model_creation(df, lo_delta=0.01, batch_size = 50, period = 5, lo_frac = 0.6, sample_size = 52, \n",
        "                   epoch=100, learning_rate=0.001, lr_decay=0.0, kernel1 = 9, kernel2 = 5, kernel3 = 3, \n",
        "                   filtro1 = 32, filtro2 = 64, filtro3 = 128):\n",
        "  \n",
        "    \"\"\"\n",
        "    df: DataFrame de pandas con los valores de la serie temporal.\n",
        "    #Hiperparametros STL\n",
        "    period: periodicidad más significativa de la serie temporal observada, en unidades de 1 observación. Ejm: para indicar una fuerte periodicidad anual con observaciones tomadas diariamente: period=365\n",
        "    lo_frac: fracción de datos a utilizar en el entrenamiento de la regresión Lowess. \n",
        "    lo_delta: distancia fraccional dentro de la cual se puede utilizar la interpolación lineal en lugar de una regresión ponderada. Usar un lo_delta que no sea cero disminuye significativamente tiempo de cálculo.\n",
        "    #Hiperparametros modelo\n",
        "    batch_size: número de ejemplos de entrenamiento utilizados en cada iteración del entrenamiento.\n",
        "    sample_size: número de observaciones previas que se tomarán como inputs.\n",
        "    epoch: número de veces en que se procesarán todos los ejemplos del conjunto de datos en una sesión de entrenamiento.\n",
        "    learning_rate: medida en la que los pesos se actualizan con respecto a la nueva información adquirida tras procesar cada batch.\n",
        "    lr_decay: tasa de decaimiento del learning_rate en cada iteración\n",
        "    kernel1-3: tamaño de la ventana (o detector de caracteristicas) que recorrerá los datos en cada capa de convolución.\n",
        "    filtro1-3: número de filtros a utilizar en cada capa de convolución.\n",
        "    \"\"\"\n",
        "  \n",
        "    \n",
        "    import numpy as np\n",
        "    np.random.seed(42) # para reproducibilidad   \n",
        "    import tensorflow as tf\n",
        "    import keras\n",
        "    #session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,\n",
        "    #                              inter_op_parallelism_threads=1)\n",
        "    from keras import backend as K\n",
        "    tf.set_random_seed(1234)\n",
        "    #sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "    #K.set_session(sess)    \n",
        "    \n",
        "    \n",
        "    from tensorflow.python.util import deprecation\n",
        "    deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
        "    \n",
        "    \n",
        "    ##DESCOMPOSICIÓN STL\n",
        "    \n",
        "    stl = decompose(df, period=period, lo_frac=lo_frac, lo_delta=lo_delta)  \n",
        "    \n",
        "    seasonal, trend, random =  np.asarray(stl.seasonal.values), np.asarray(stl.trend.values), np.asarray(stl.resid.values)\n",
        "    \n",
        "    #DEFINICIÓN DEL MODELO\n",
        "\n",
        "#    sample_size = 52 # features (in this case, previous information you want consider for your predictions)\n",
        "\n",
        "    #kernel_sz = [9,5,3]\n",
        "    \n",
        "    kernel_sz = [int(kernel1), int(kernel2), int(kernel3)]\n",
        "    \n",
        "#    filtros = [32,64,128]\n",
        "\n",
        "    filtros = [filtro1,filtro2,filtro3]\n",
        "    \n",
        "    # CNN para seas\n",
        "    inputseas = Input(shape=(sample_size, 1))\n",
        "    convseas = Convolution1D(filtros[0], kernel_sz[0], activation='relu')(inputseas)\n",
        "    convseas = MaxPooling1D(pool_size =2)(convseas)\n",
        "    convseas = Convolution1D(filtros[1], kernel_sz[1], activation='relu')(convseas)\n",
        "    convseas = MaxPooling1D(pool_size =2)(convseas)\n",
        "    convseas = Convolution1D(filtros[2], kernel_sz[2], activation='relu')(convseas)\n",
        "    convseas = MaxPooling1D(pool_size =2)(convseas)\n",
        "    convseas = Flatten()(convseas)\n",
        "\n",
        "\n",
        "    # CNN para trend\n",
        "    inputtrend = Input(shape=(sample_size, 1))\n",
        "    convtrend = Convolution1D(filtros[0], kernel_sz[0], activation='relu')(inputtrend)\n",
        "    convtrend = MaxPooling1D(pool_size =2)(convtrend)\n",
        "    convtrend = Convolution1D(filtros[1], kernel_sz[1], activation='relu')(convtrend)\n",
        "    convtrend = MaxPooling1D(pool_size =2)(convtrend)\n",
        "    convtrend = Convolution1D(filtros[2], kernel_sz[2], activation='relu')(convtrend)\n",
        "    convtrend = MaxPooling1D(pool_size =2)(convtrend)\n",
        "    convtrend = Flatten()(convtrend)\n",
        "\n",
        "    # CNN para rand\n",
        "    inputrand = Input(shape=(sample_size, 1))\n",
        "    convrand = Convolution1D(filtros[0], kernel_sz[0], activation='relu')(inputrand)\n",
        "    convrand = MaxPooling1D(pool_size =2)(convrand)\n",
        "    convrand = Convolution1D(filtros[1], kernel_sz[1], activation='relu')(convrand)\n",
        "    convrand = MaxPooling1D(pool_size =2)(convrand)\n",
        "    convrand = Convolution1D(filtros[2], kernel_sz[2], activation='relu')(convrand)\n",
        "    convrand = MaxPooling1D(pool_size =2)(convrand)\n",
        "    convrand = Flatten()(convrand)\n",
        "\n",
        "    merged = concatenate([convseas, convtrend, convrand],axis=1)\n",
        "    out = Dense(64)(merged)\n",
        "    out = Dense(16)(out)\n",
        "    out = Dense(1, activation='linear')(out)\n",
        "\n",
        "    final_model = Model(inputs=[inputseas, inputtrend, inputrand], outputs=[out])\n",
        "\n",
        "    # Compilar\n",
        "    adam = Adam(lr=learning_rate, decay=lr_decay)\n",
        "    final_model.compile(loss=\"mse\", optimizer=adam)\n",
        "\n",
        "    ####\n",
        "    \n",
        "    # ENTRENAMIENTO DEL MODELO\n",
        "\n",
        "    \n",
        "    dataset = np.asarray(df.values)\n",
        "    \n",
        "    #seasonal = np.asarray(seasonal)\n",
        "    #trend = np.asarray(trend)\n",
        "    #random = np.asarray(random)\n",
        "\n",
        "    y = dataset[sample_size:]\n",
        "\n",
        "    Xseas = np.atleast_3d(np.array([seasonal[start:start + sample_size] for start in range(0, seasonal.shape[0]-sample_size)]))\n",
        "    Xtre = np.atleast_3d(np.array([trend[start:start + sample_size] for start in range(0, trend.shape[0]-sample_size)]))\n",
        "    Xrand = np.atleast_3d(np.array([random[start:start + sample_size] for start in range(0, random.shape[0]-sample_size)]))\n",
        "\n",
        "    test_size = int(len(dataset)*0.3)\n",
        "\n",
        "    trainY, testY = y[:-test_size], y[-test_size:]\n",
        "\n",
        "    trainXseas = Xseas[:-test_size]\n",
        "    testXseas =  Xseas[-test_size:]\n",
        "\n",
        "    trainXtre = Xtre[:-test_size]\n",
        "    testXtre =  Xtre[-test_size:]\n",
        "\n",
        "    trainXrand = Xrand[:-test_size]\n",
        "    testXrand =  Xrand[-test_size:]\n",
        "\n",
        "    nextSteps = np.empty((1,sample_size,1))\n",
        "    nextSteps[0,:,:]= np.atleast_3d(np.array([dataset[start:start + sample_size]\n",
        "                                              for start in range(dataset.shape[0]-sample_size,dataset.shape[0]-sample_size+1)]))\n",
        "\n",
        "    final_model.fit([trainXseas,trainXtre,trainXrand], trainY, epochs=epoch, batch_size=batch_size, verbose=0) \n",
        "    \n",
        "    pred = final_model.predict([testXseas,testXtre,testXrand])\n",
        "\n",
        "    testScore = mean_squared_error(testY, pred)\n",
        "    \n",
        "    clear_session()\n",
        "    gc.collect()\n",
        "    \n",
        "    return testScore, final_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhM6qJZ68wsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as nump\n",
        "\n",
        "##Devuelve el numero de bits minimos necesarios para representar un número decimal.\n",
        "\n",
        "def num_bits(num_dec):    \n",
        "    res= 2**(num_dec - 1).bit_length()\n",
        "    if num_dec == res: \n",
        "        num_dec+=1\n",
        "        res= 1 if num_dec == 0 else 2**(num_dec - 1).bit_length()\n",
        "    res= int(res/2)\n",
        "    \n",
        "    return len(entero_a_binario(res))\n",
        "\n",
        "#Toma un resultado obtenido en decimales y lo ubicar dentro del rango definido para su hiperparametro correspondiente.\n",
        "def resultado_a_rango(num_dec, hiperparametro):\n",
        "    resul = num_dec * hiperparametro[3] + hiperparametro[1]\n",
        "    if resul>hiperparametro[2]: resul = hiperparametro[2]\n",
        "    return resul\n",
        "\n",
        "\n",
        "#Convierte una cadena de números binarios a código Gray. \n",
        "def binario_a_gray(num): \n",
        "    return num ^ (num >> 1) \n",
        "\n",
        "#Convierte una cadena de números binarios en formato Gray a entero.\n",
        "def gray_a_entero(num_gray):\n",
        "    num = binario_a_entero(num_gray)\n",
        "    inv = 0; \n",
        "    while(num): \n",
        "        inv = inv ^ num; \n",
        "        num = num >> 1; \n",
        "    return inv;\n",
        "    \n",
        "def entero_a_binario(num):\n",
        "    return [int(x) for x in bin(num)[2:]]\n",
        "    \n",
        "#Convierte una cadena binaria a una variable entera\n",
        "def binario_a_entero(num_bit):\n",
        "    out = 0\n",
        "    for bit in num_bit:\n",
        "        out = (out << 1) | bit\n",
        "    return out\n",
        "\n",
        "#Genera números aleatorios y los compara con los valores de un vector \"prob\"\n",
        "def get_num(prob, indx=0):\n",
        "    vec = [None] * len(prob)\n",
        "    \"\"\"\n",
        "    Returns 0 (False) or 1 (True) depending on prob, if all 0s then run again\n",
        "    \"\"\"\n",
        "    for i in range(len(prob)):\n",
        "        vec[i]= rn.random() < prob[i]\n",
        "\n",
        "    if indx ==1:\n",
        "        if (gray_a_entero(vec)>10):\n",
        "            vec = get_num(prob)\n",
        "    return vec\n",
        "\n",
        "#Creamos un array de longitud vec_len, correspondiente al vector de probabilidades.\n",
        "#Al principio la probabiidad de 1 o 0 es 0.5 siempre.\n",
        "def crea_prob_inicial(vec_len):\n",
        "    return nump.full(vec_len, 0.5, dtype=float)\n",
        "\n",
        "#Inicializa la población (con valores 0).\n",
        "def pob_ini(num_pob, vec_len):\n",
        "    return nump.zeros((num_pob, vec_len), dtype=int)\n",
        "\n",
        "#Inicialización de los valores de la función fitness (comienzan valiendo None)\n",
        "def scores_ini(num_pob):\n",
        "    return [None for _ in range(num_pob)]\n",
        "\n",
        "#Procesa el vector binario de un individuo y devuelve los valores de sus hiperparametros en decimales.\n",
        "\n",
        "def proc_bin(bin_vector):\n",
        "    global hiperparametros, hiperparametros_int_aux\n",
        "    flag=0\n",
        "    dec_resul=[]\n",
        "    for i, hiper in enumerate(hiperparametros):\n",
        "        dec_resul.append(resultado_a_rango(gray_a_entero(bin_vector[flag : flag + hiperparametros_int_aux[i][2]]),hiper))\n",
        "        flag += hiperparametros_int_aux[i][2]\n",
        "        \n",
        "    return dec_resul\n",
        "\n",
        "#Funcion encargada de procesar el vector binario de cada individuo, definir y entrenar su modelo correspondiente, y devolver su MSE. \n",
        "\n",
        "def fitness(bin_num):\n",
        "  \n",
        "    # dec_resul convierte el número binario de cada hiperparametro a una lista con su correspondencia en decimal\n",
        "    dec_resul = proc_bin(bin_num)\n",
        "    \n",
        "    hiper_inputs = {}\n",
        "    for i, v in enumerate(dec_resul):\n",
        "        hiper_inputs[hiperparametros_int_aux[i][0]] = v\n",
        "    \n",
        "    loss, modelo = model_creation(df, **hiper_inputs)\n",
        "   \n",
        "    gc.collect()\n",
        "    \n",
        "    return loss, modelo, hiper_inputs\n",
        "\n",
        "\n",
        "#Convertir la lista de hiperparametros a una lista con el nombre, el número total de posibles valores, y el número de\n",
        "#bits minimo necesario para representarlo\n",
        "\n",
        "hiperparametros_int_aux= []\n",
        "for h in hiperparametros:\n",
        "    hiperparametros_int_aux.append([h[0], math.ceil((h[2]-h[1])/h[3]), num_bits(math.ceil((h[2]-h[1])/h[3]))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "vS7sgI8J8wsN",
        "colab_type": "code",
        "outputId": "ca9fa495-6095-474e-b29b-71fcfe0e80d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "mejor = pbil_optimizacion(learn_rate=0.02,\n",
        "                   learn_rate_neg=0.02,\n",
        "                   num_pob=15,\n",
        "                   num_mejores_para_actualizar_vec =3,\n",
        "                   num_peores_para_actualizar_vec =3,\n",
        "                   vec_len=sum([h[2] for h in hiperparametros_int_aux]),\n",
        "                   ciclos_optimizacion=20,\n",
        "                   eval_f=fitness)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0706 00:17:12.131129 139847339415424 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0706 00:17:12.132940 139847339415424 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0706 00:17:12.141703 139847339415424 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0706 00:17:12.163319 139847339415424 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0706 00:17:12.380431 139847339415424 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0706 00:17:12.680696 139847339415424 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "W0706 00:17:13.080239 139847339415424 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Paso: 0\n",
            "Vector de prob: [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
            " 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
            " 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            "Mejores: [113.38805392255414, 140.81116324784793, 146.9333894041778]\n",
            "Peores: [4882.691697753113, 5180.032360112789, 5803.169978607052]\n",
            "Mejor de todos: 113.38805392255414\n",
            "--------------\n",
            "Paso: 1\n",
            "Vector de prob: [0.38 0.46 0.58 0.42 0.54 0.5  0.5  0.58 0.5  0.5  0.46 0.58 0.46 0.54\n",
            " 0.5  0.5  0.5  0.54 0.54 0.46 0.5  0.46 0.5  0.46 0.54 0.5  0.5  0.5\n",
            " 0.5  0.54 0.54 0.46 0.38 0.46 0.54 0.46 0.42 0.54 0.54 0.54 0.54 0.58\n",
            " 0.46 0.58 0.54 0.5  0.5  0.42 0.42 0.46 0.5  0.5  0.54 0.46]\n",
            "Mejores: [128.48149438615656, 148.08019737733977, 148.35242624889284]\n",
            "Peores: [3035.6754279991046, 4075.558147659851, 5731.579538640197]\n",
            "Mejor de todos: 113.38805392255414\n",
            "--------------\n",
            "Paso: 2\n",
            "Vector de prob: [0.38 0.46 0.58 0.46 0.54 0.5  0.58 0.66 0.5  0.5  0.5  0.66 0.5  0.58\n",
            " 0.42 0.54 0.54 0.54 0.54 0.54 0.54 0.42 0.54 0.42 0.58 0.5  0.5  0.46\n",
            " 0.54 0.5  0.58 0.46 0.38 0.58 0.5  0.46 0.46 0.54 0.66 0.58 0.54 0.58\n",
            " 0.42 0.54 0.46 0.5  0.54 0.38 0.38 0.5  0.54 0.46 0.5  0.46]\n",
            "Mejores: [134.19361815311834, 148.06995352562336, 148.08535908558406]\n",
            "Peores: [6023.381773005714, 6143.539993228119, 6360.168565260702]\n",
            "Mejor de todos: 113.38805392255414\n",
            "--------------\n",
            "Paso: 3\n",
            "Vector de prob: [0.26 0.46 0.54 0.5  0.58 0.54 0.54 0.58 0.46 0.46 0.46 0.66 0.42 0.54\n",
            " 0.46 0.54 0.54 0.5  0.58 0.5  0.5  0.34 0.5  0.42 0.7  0.5  0.54 0.42\n",
            " 0.58 0.58 0.54 0.42 0.34 0.54 0.5  0.46 0.38 0.46 0.74 0.62 0.46 0.46\n",
            " 0.38 0.5  0.5  0.5  0.5  0.42 0.42 0.46 0.54 0.38 0.5  0.58]\n",
            "Mejores: [147.01882379643874, 148.44191219879755, 148.4995017032889]\n",
            "Peores: [4219.635402541527, 5381.421277250658, 6364.721653313713]\n",
            "Mejor de todos: 113.38805392255414\n",
            "--------------\n",
            "Paso: 4\n",
            "Vector de prob: [0.26 0.54 0.5  0.5  0.62 0.54 0.62 0.62 0.46 0.46 0.46 0.66 0.42 0.46\n",
            " 0.46 0.54 0.5  0.42 0.62 0.54 0.46 0.34 0.54 0.34 0.74 0.62 0.62 0.38\n",
            " 0.54 0.54 0.5  0.38 0.38 0.54 0.58 0.46 0.38 0.46 0.74 0.58 0.42 0.34\n",
            " 0.34 0.42 0.38 0.46 0.5  0.46 0.46 0.46 0.54 0.34 0.54 0.66]\n",
            "Mejores: [148.14387807065347, 149.48531734589986, 151.28929039870704]\n",
            "Peores: [5351.179072515027, 5805.90159787588, 6081.491230172253]\n",
            "Mejor de todos: 113.38805392255414\n",
            "--------------\n",
            "Paso: 5\n",
            "Vector de prob: [0.34 0.5  0.5  0.58 0.66 0.5  0.58 0.62 0.5  0.5  0.42 0.66 0.5  0.54\n",
            " 0.42 0.58 0.54 0.38 0.66 0.54 0.42 0.3  0.58 0.38 0.78 0.62 0.62 0.38\n",
            " 0.54 0.62 0.58 0.34 0.46 0.62 0.54 0.46 0.3  0.5  0.7  0.58 0.42 0.38\n",
            " 0.3  0.38 0.26 0.5  0.5  0.5  0.42 0.46 0.5  0.38 0.58 0.7 ]\n",
            "Mejores: [133.31963085709518, 146.21105309160708, 149.94828954323683]\n",
            "Peores: [5866.262184220608, 6188.817219013068, 6253.936769390443]\n",
            "Mejor de todos: 113.38805392255414\n",
            "--------------\n",
            "Paso: 6\n",
            "Vector de prob: [0.34 0.5  0.46 0.58 0.7  0.5  0.54 0.62 0.5  0.58 0.38 0.78 0.5  0.46\n",
            " 0.38 0.62 0.54 0.34 0.62 0.54 0.34 0.3  0.62 0.42 0.86 0.66 0.74 0.34\n",
            " 0.58 0.54 0.5  0.38 0.42 0.62 0.54 0.5  0.3  0.46 0.66 0.58 0.38 0.38\n",
            " 0.3  0.34 0.22 0.5  0.46 0.54 0.38 0.38 0.54 0.3  0.62 0.7 ]\n",
            "Mejores: [140.25850911649826, 146.79713542387344, 148.8781295108417]\n",
            "Peores: [3227.5962576780034, 4121.477594131415, 4675.042819323443]\n",
            "Mejor de todos: 113.38805392255414\n",
            "--------------\n",
            "Paso: 7\n",
            "Vector de prob: [0.38 0.5  0.42 0.58 0.78 0.5  0.62 0.62 0.46 0.5  0.34 0.82 0.46 0.42\n",
            " 0.38 0.62 0.46 0.34 0.66 0.58 0.3  0.3  0.58 0.38 0.9  0.7  0.74 0.22\n",
            " 0.62 0.54 0.5  0.38 0.46 0.58 0.58 0.42 0.34 0.5  0.62 0.5  0.34 0.42\n",
            " 0.3  0.34 0.18 0.42 0.54 0.5  0.38 0.3  0.62 0.3  0.54 0.74]\n",
            "Mejores: [148.02910353457736, 148.02959744800668, 148.03091107005656]\n",
            "Peores: [2694.7562956409356, 4164.54574778184, 5702.530973772618]\n",
            "Mejor de todos: 113.38805392255414\n",
            "--------------\n",
            "Paso: 8\n",
            "Vector de prob: [0.38 0.54 0.42 0.58 0.74 0.5  0.66 0.58 0.5  0.46 0.38 0.86 0.5  0.34\n",
            " 0.42 0.66 0.5  0.3  0.7  0.5  0.3  0.22 0.54 0.46 0.94 0.66 0.74 0.18\n",
            " 0.7  0.46 0.42 0.38 0.46 0.5  0.58 0.46 0.38 0.42 0.66 0.5  0.38 0.38\n",
            " 0.22 0.3  0.22 0.38 0.58 0.46 0.3  0.42 0.66 0.34 0.46 0.78]\n",
            "Mejores: [141.79950823164535, 144.96534797524774, 147.80831593180503]\n",
            "Peores: [325.03840780319257, 353.77379357809457, 1022.824654815426]\n",
            "Mejor de todos: 113.38805392255414\n",
            "--------------\n",
            "Paso: 9\n",
            "Vector de prob: [0.38 0.5  0.38 0.58 0.74 0.62 0.74 0.66 0.54 0.46 0.34 0.82 0.46 0.3\n",
            " 0.38 0.7  0.5  0.3  0.66 0.46 0.34 0.22 0.58 0.42 0.94 0.66 0.74 0.22\n",
            " 0.66 0.5  0.42 0.38 0.42 0.5  0.54 0.46 0.34 0.46 0.62 0.5  0.34 0.38\n",
            " 0.22 0.3  0.22 0.38 0.58 0.54 0.26 0.5  0.74 0.3  0.42 0.82]\n",
            "Mejores: [142.73996237384657, 143.6542812552554, 144.2893506129663]\n",
            "Peores: [258.2091691552445, 298.766752388687, 359.9734311120357]\n",
            "Mejor de todos: 113.38805392255414\n",
            "--------------\n",
            "Paso: 10\n",
            "Vector de prob: [0.34 0.5  0.38 0.54 0.66 0.7  0.74 0.66 0.58 0.46 0.38 0.86 0.46 0.26\n",
            " 0.42 0.62 0.5  0.3  0.66 0.5  0.34 0.26 0.58 0.38 0.94 0.62 0.82 0.26\n",
            " 0.66 0.46 0.34 0.34 0.5  0.54 0.66 0.5  0.38 0.54 0.62 0.54 0.34 0.5\n",
            " 0.22 0.38 0.22 0.38 0.62 0.46 0.26 0.42 0.7  0.26 0.54 0.82]\n",
            "Mejores: [148.02642699093983, 156.50319019113607, 163.71062808478624]\n",
            "Peores: [441.75567656150747, 756.2797676223166, 761.8410768412817]\n",
            "Mejor de todos: 113.38805392255414\n",
            "--------------\n",
            "Paso: 11\n",
            "Vector de prob: [0.34 0.58 0.42 0.54 0.62 0.74 0.74 0.58 0.58 0.42 0.42 0.86 0.46 0.26\n",
            " 0.38 0.58 0.5  0.3  0.66 0.5  0.34 0.22 0.62 0.42 0.94 0.62 0.78 0.34\n",
            " 0.62 0.42 0.34 0.34 0.5  0.54 0.62 0.46 0.34 0.46 0.66 0.54 0.34 0.5\n",
            " 0.18 0.42 0.18 0.34 0.62 0.5  0.22 0.38 0.74 0.26 0.46 0.82]\n",
            "Mejores: [104.7226269569646, 115.4073906314322, 148.10005866084325]\n",
            "Peores: [254.05388128298242, 462.42112854577323, 3691.259800614425]\n",
            "Mejor de todos: 104.7226269569646\n",
            "--------------\n",
            "Paso: 12\n",
            "Vector de prob: [0.34 0.46 0.42 0.46 0.58 0.78 0.78 0.58 0.58 0.46 0.42 0.9  0.5  0.22\n",
            " 0.42 0.58 0.5  0.34 0.66 0.42 0.38 0.22 0.66 0.38 0.9  0.58 0.82 0.34\n",
            " 0.54 0.42 0.38 0.3  0.58 0.54 0.58 0.54 0.3  0.38 0.58 0.54 0.3  0.5\n",
            " 0.18 0.42 0.18 0.34 0.62 0.42 0.18 0.34 0.74 0.22 0.42 0.82]\n",
            "Mejores: [147.77993780768904, 147.8537173815005, 148.05047371542963]\n",
            "Peores: [419.12205037203057, 3842.571633962085, 5839.616109658425]\n",
            "Mejor de todos: 104.7226269569646\n",
            "--------------\n",
            "Paso: 13\n",
            "Vector de prob: [0.34 0.46 0.38 0.46 0.58 0.78 0.74 0.54 0.58 0.42 0.42 0.9  0.46 0.14\n",
            " 0.38 0.62 0.54 0.38 0.58 0.46 0.46 0.18 0.66 0.38 0.9  0.58 0.78 0.34\n",
            " 0.58 0.42 0.38 0.34 0.62 0.54 0.5  0.62 0.3  0.38 0.62 0.5  0.3  0.46\n",
            " 0.22 0.34 0.14 0.34 0.66 0.46 0.18 0.34 0.7  0.26 0.5  0.82]\n",
            "Mejores: [147.71786439903428, 148.0582467272769, 148.50417186994886]\n",
            "Peores: [1651.9916398446508, 3058.088027445607, 5073.651153775476]\n",
            "Mejor de todos: 104.7226269569646\n",
            "--------------\n",
            "Paso: 14\n",
            "Vector de prob: [0.34 0.38 0.3  0.42 0.5  0.82 0.82 0.5  0.62 0.38 0.42 0.86 0.54 0.18\n",
            " 0.38 0.66 0.54 0.46 0.5  0.46 0.42 0.22 0.66 0.38 0.94 0.62 0.82 0.3\n",
            " 0.58 0.42 0.3  0.42 0.62 0.46 0.54 0.62 0.38 0.3  0.66 0.42 0.34 0.42\n",
            " 0.22 0.34 0.14 0.34 0.7  0.5  0.1  0.38 0.62 0.22 0.5  0.82]\n",
            "Mejores: [109.17613272188918, 148.04515596509793, 148.88887705102144]\n",
            "Peores: [1018.8599113311399, 1231.036036481123, 3437.922845677543]\n",
            "Mejor de todos: 104.7226269569646\n",
            "--------------\n",
            "Paso: 15\n",
            "Vector de prob: [0.38 0.38 0.3  0.34 0.5  0.82 0.82 0.54 0.66 0.38 0.46 0.86 0.62 0.14\n",
            " 0.38 0.66 0.54 0.5  0.42 0.5  0.46 0.22 0.62 0.3  0.94 0.66 0.82 0.26\n",
            " 0.58 0.42 0.34 0.46 0.66 0.42 0.54 0.7  0.38 0.3  0.62 0.42 0.34 0.38\n",
            " 0.26 0.3  0.1  0.26 0.66 0.54 0.06 0.38 0.58 0.18 0.58 0.78]\n",
            "Mejores: [148.1078065936552, 148.4838721087216, 155.0909146315081]\n",
            "Peores: [930.2347571167312, 1194.6157123287544, 6233.85196710657]\n",
            "Mejor de todos: 104.7226269569646\n",
            "--------------\n",
            "Paso: 16\n",
            "Vector de prob: [0.42 0.38 0.26 0.38 0.54 0.86 0.86 0.54 0.7  0.38 0.5  0.86 0.58 0.14\n",
            " 0.38 0.62 0.58 0.5  0.38 0.5  0.46 0.22 0.66 0.3  0.98 0.7  0.82 0.22\n",
            " 0.62 0.42 0.3  0.46 0.58 0.46 0.54 0.66 0.3  0.3  0.66 0.42 0.3  0.38\n",
            " 0.26 0.3  0.14 0.18 0.66 0.62 0.02 0.34 0.5  0.18 0.58 0.74]\n",
            "Mejores: [145.27737504139625, 148.00862264386137, 148.36778240185004]\n",
            "Peores: [352.96785093606815, 4482.6987894344375, 5170.471335991496]\n",
            "Mejor de todos: 104.7226269569646\n",
            "--------------\n",
            "Paso: 17\n",
            "Vector de prob: [0.42 0.38 0.3  0.38 0.5  0.82 0.86 0.54 0.7  0.38 0.54 0.86 0.5  0.06\n",
            " 0.42 0.62 0.66 0.54 0.34 0.46 0.5  0.26 0.7  0.34 0.98 0.7  0.82 0.22\n",
            " 0.62 0.42 0.3  0.46 0.54 0.38 0.54 0.74 0.3  0.3  0.7  0.42 0.3  0.38\n",
            " 0.22 0.3  0.14 0.1  0.78 0.58 0.01 0.34 0.5  0.18 0.62 0.74]\n",
            "Mejores: [137.86929525838286, 140.6835807299713, 146.36974600715754]\n",
            "Peores: [355.52812207099475, 1562.8901227123963, 6087.838365163023]\n",
            "Mejor de todos: 104.7226269569646\n",
            "--------------\n",
            "Paso: 18\n",
            "Vector de prob: [0.46 0.34 0.3  0.42 0.54 0.74 0.86 0.54 0.66 0.42 0.58 0.94 0.58 0.1\n",
            " 0.46 0.66 0.7  0.58 0.26 0.38 0.5  0.22 0.74 0.34 0.98 0.7  0.82 0.3\n",
            " 0.7  0.42 0.26 0.46 0.58 0.42 0.5  0.7  0.26 0.26 0.74 0.38 0.26 0.42\n",
            " 0.18 0.26 0.06 0.06 0.74 0.46 0.01 0.3  0.5  0.18 0.62 0.78]\n",
            "Mejores: [145.53946395910287, 148.04799511392264, 148.09333632485456]\n",
            "Peores: [266.420485523903, 309.7455654575115, 1797.8523874826315]\n",
            "Mejor de todos: 104.7226269569646\n",
            "--------------\n",
            "Paso: 19\n",
            "Vector de prob: [0.46 0.46 0.18 0.54 0.54 0.7  0.86 0.54 0.66 0.46 0.58 0.94 0.58 0.1\n",
            " 0.5  0.66 0.7  0.54 0.26 0.38 0.54 0.26 0.78 0.38 0.98 0.74 0.86 0.26\n",
            " 0.7  0.38 0.3  0.54 0.58 0.46 0.54 0.7  0.34 0.3  0.74 0.38 0.26 0.38\n",
            " 0.18 0.22 0.06 0.06 0.78 0.5  0.01 0.34 0.54 0.14 0.62 0.78]\n",
            "Mejores: [133.77276593547273, 147.70063294300675, 148.30449061353417]\n",
            "Peores: [564.4956794289536, 576.8094565292499, 3909.5002071638646]\n",
            "Mejor de todos: 104.7226269569646\n",
            "--------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buNLm0TUn06e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}